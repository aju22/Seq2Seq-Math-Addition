{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Seq2Seq for Math.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM1mx7RlJzXgKJBmzQf/7W7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aju22/Seq2Seq-Math-Addition/blob/main/Seq2Seq_for_Math.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Use GPU"
      ],
      "metadata": {
        "id": "DVF_JLblbYNd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cq86998YbX0c",
        "outputId": "7561bf4a-bfae-46f4-c158-ff31e3153cc0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Generation"
      ],
      "metadata": {
        "id": "Y0nq73uW4KpC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "FSGBuWTz4w4O"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N_ADDED = 2\n",
        "LARGEST= 100\n",
        "TRAIN_SAMPLES = 10000\n",
        "TEST_SAMPLES = 100"
      ],
      "metadata": {
        "id": "WWqbfeA16CAz"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "zwEj4PRl1Hdc"
      },
      "outputs": [],
      "source": [
        "def random_sum_data(samples, n_added, largest):\n",
        "  X = []\n",
        "  y = []\n",
        "  for i in range(samples):\n",
        "    num_seq = [np.random.randint(1, largest) for j in range(n_added)]\n",
        "    sum_of_seq = [sum(num_seq)]\n",
        "\n",
        "    X.append(num_seq)\n",
        "    y.append(sum_of_seq)\n",
        "\n",
        "  return X, y  "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert Data to String and Padding"
      ],
      "metadata": {
        "id": "iSOLLYGx9xxV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_input_seq_length = N_ADDED * np.ceil(np.log10(LARGEST+1)) + N_ADDED - 1\n",
        "max_output_seq_length = np.ceil(np.log10(N_ADDED * (LARGEST+1)))\n",
        "\n",
        "print(\"Max input length : {}\".format(max_input_seq_length))\n",
        "print(\"Max output length : {}\".format(max_output_seq_length))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9oXwhkZf5m51",
        "outputId": "dd8b4e6e-fecd-4dd1-c553-d424c1a0170c"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max input length : 7.0\n",
            "Max output length : 3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def data_to_string(X, y):\n",
        "  X_str = []\n",
        "  y_str = []\n",
        "  \n",
        "  for i in range(len(X)):\n",
        "    \n",
        "    data = X[i]\n",
        "    data_str = \"+\".join([str(x) for x in data])\n",
        "    \n",
        "    if len(data_str) < max_input_seq_length:\n",
        "      diff = max_input_seq_length - len(data_str)\n",
        "      data_str += int(diff)*\" \"\n",
        "    \n",
        "    X_str.append(data_str)\n",
        "    \n",
        "    result_str = str(y[i][0])\n",
        "\n",
        "    if len(result_str) < max_output_seq_length:\n",
        "      diff = max_output_seq_length - len(result_str)\n",
        "      result_str += int(diff)*\" \"\n",
        "\n",
        "    y_str.append(result_str)\n",
        "\n",
        "  return X_str, y_str"
      ],
      "metadata": {
        "id": "2y1NTrta6fUp"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encode Strings"
      ],
      "metadata": {
        "id": "QP8t_-Y090Tr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "char2int = {'0' : 0, '1' : 1, '2' : 2, '3' : 3, '4' : 4, '5' : 5, '6' : 6, '7' : 7, '8' : 8, '9' : 9, '+' : 10, \" \" : 11}"
      ],
      "metadata": {
        "id": "esMUW-me8rcx"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "int2char = {v : k for k, v in char2int.items()}"
      ],
      "metadata": {
        "id": "SM7f8cDmUhBW"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode(X_str, y_str):\n",
        "  X_encoded = []\n",
        "  y_encoded = []\n",
        "  for i in range(len(X_str)):\n",
        "    data_str = X_str[i]\n",
        "    data_encoded = [char2int[char] for char in data_str]\n",
        "    X_encoded.append(data_encoded)\n",
        "\n",
        "    result_str = y_str[i]\n",
        "    result_encoded = [char2int[char] for char in result_str]\n",
        "    y_encoded.append(result_encoded)\n",
        "    \n",
        "  return X_encoded, y_encoded"
      ],
      "metadata": {
        "id": "JovUSVuE-BDv"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# One-Hot-Encoding"
      ],
      "metadata": {
        "id": "qsrphqx_NYLC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "evJd_mPJPtkz"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N_CLASSES = 12"
      ],
      "metadata": {
        "id": "9E5gaI3BYuiZ"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot_encode(X_encoded, y_encoded):\n",
        "  X_ohe = []\n",
        "  y_ohe = []\n",
        "  for i in range(len(X_encoded)):\n",
        "    \n",
        "    X_ohe.append(to_categorical(X_encoded[i], num_classes = N_CLASSES))\n",
        "    y_ohe.append(to_categorical(y_encoded[i], num_classes = N_CLASSES))\n",
        "\n",
        "  return np.array(X_ohe), np.array(y_ohe)"
      ],
      "metadata": {
        "id": "2K1gfRZKAEeU"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Generator"
      ],
      "metadata": {
        "id": "cH19-xCwa-Cx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_data(samples, n_added, largest):\n",
        "  \n",
        "  X, y = random_sum_data(samples = samples, n_added = n_added, largest = largest)\n",
        "\n",
        "  X_str, y_str = data_to_string(X, y)\n",
        "\n",
        "  X_encoded, y_encoded = encode(X_str, y_str)\n",
        "  \n",
        "  X_ohe, y_ohe = one_hot_encode(X_encoded, y_encoded)\n",
        "\n",
        "  return X_ohe, y_ohe"
      ],
      "metadata": {
        "id": "R0x8ImgxbDTN"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = generate_data(TRAIN_SAMPLES, N_ADDED, LARGEST)\n",
        "X_test, y_test = generate_data(TEST_SAMPLES, N_ADDED, LARGEST)"
      ],
      "metadata": {
        "id": "C7LPdXgPb9Qm"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decoding Sequence"
      ],
      "metadata": {
        "id": "4UQDjiFTXL0m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def decode(sequence):\n",
        "  string = \"\"\n",
        "  \n",
        "  for ohe in sequence:\n",
        "    idx = np.argmax(ohe)\n",
        "    char = int2char[idx]\n",
        "    string += char\n",
        "  \n",
        "  return string"
      ],
      "metadata": {
        "id": "ncn4snTBT-uP"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Architecture"
      ],
      "metadata": {
        "id": "myOejoDDXX8A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, TimeDistributed, RepeatVector, Dense"
      ],
      "metadata": {
        "id": "Ma4q0JyQXaOe"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.device(device_name):\n",
        "\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(LSTM(100, input_shape=(int(max_input_seq_length), N_CLASSES)))\n",
        "  model.add(RepeatVector(int(max_output_seq_length)))\n",
        "  model.add(LSTM(50, return_sequences=True))\n",
        "  model.add(TimeDistributed(Dense(N_CLASSES, activation='softmax')))\n",
        "\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQZ7KemxXffs",
        "outputId": "f3d0fe1b-c3fb-4cf4-b281-a2f40d5970de"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_6 (LSTM)               (None, 100)               45200     \n",
            "                                                                 \n",
            " repeat_vector_3 (RepeatVect  (None, 3, 100)           0         \n",
            " or)                                                             \n",
            "                                                                 \n",
            " lstm_7 (LSTM)               (None, 3, 50)             30200     \n",
            "                                                                 \n",
            " time_distributed_3 (TimeDis  (None, 3, 12)            612       \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 76,012\n",
            "Trainable params: 76,012\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    tf.keras.callbacks.ModelCheckpoint(\"model_cpkt.h5\", save_best_only=True),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, verbose=0, mode='auto', min_delta=0.0001, cooldown=0, min_lr=0),\n",
        "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=50)\n",
        "]"
      ],
      "metadata": {
        "id": "tL2yycYYghTC"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training"
      ],
      "metadata": {
        "id": "TRWQWpNWZ_k7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 100\n",
        "EPOCH = 1000\n",
        "\n",
        "with tf.device(device_name):  \n",
        "  history = model.fit(X_train, y_train, \n",
        "                      epochs = EPOCH, \n",
        "                      batch_size=BATCH_SIZE,\n",
        "                      validation_data = [X_test, y_test],\n",
        "                      callbacks = callbacks)"
      ],
      "metadata": {
        "id": "UU7OjmBsZgi7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "337c9ca3-1e41-4fbe-91a7-5446d0327967"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "100/100 [==============================] - 5s 17ms/step - loss: 2.1201 - accuracy: 0.3126 - val_loss: 1.9016 - val_accuracy: 0.3567 - lr: 0.0010\n",
            "Epoch 2/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 1.8152 - accuracy: 0.3832 - val_loss: 1.7579 - val_accuracy: 0.4167 - lr: 0.0010\n",
            "Epoch 3/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 1.7204 - accuracy: 0.3954 - val_loss: 1.6899 - val_accuracy: 0.4400 - lr: 0.0010\n",
            "Epoch 4/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 1.6628 - accuracy: 0.4078 - val_loss: 1.6337 - val_accuracy: 0.4500 - lr: 0.0010\n",
            "Epoch 5/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 1.5612 - accuracy: 0.4346 - val_loss: 1.5267 - val_accuracy: 0.4700 - lr: 0.0010\n",
            "Epoch 6/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 1.4673 - accuracy: 0.4575 - val_loss: 1.4381 - val_accuracy: 0.4700 - lr: 0.0010\n",
            "Epoch 7/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 1.3745 - accuracy: 0.4867 - val_loss: 1.3964 - val_accuracy: 0.4667 - lr: 0.0010\n",
            "Epoch 8/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 1.3094 - accuracy: 0.5182 - val_loss: 1.3294 - val_accuracy: 0.5033 - lr: 0.0010\n",
            "Epoch 9/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 1.2655 - accuracy: 0.5334 - val_loss: 1.2783 - val_accuracy: 0.5367 - lr: 0.0010\n",
            "Epoch 10/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 1.2500 - accuracy: 0.5379 - val_loss: 1.2505 - val_accuracy: 0.5467 - lr: 0.0010\n",
            "Epoch 11/1000\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 1.1911 - accuracy: 0.5688 - val_loss: 1.2133 - val_accuracy: 0.6000 - lr: 0.0010\n",
            "Epoch 12/1000\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.1820 - accuracy: 0.5651 - val_loss: 1.1847 - val_accuracy: 0.5867 - lr: 0.0010\n",
            "Epoch 13/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 1.1513 - accuracy: 0.5779 - val_loss: 1.1536 - val_accuracy: 0.5800 - lr: 0.0010\n",
            "Epoch 14/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 1.1064 - accuracy: 0.6028 - val_loss: 1.1436 - val_accuracy: 0.5933 - lr: 0.0010\n",
            "Epoch 15/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 1.0927 - accuracy: 0.5997 - val_loss: 1.0953 - val_accuracy: 0.6233 - lr: 0.0010\n",
            "Epoch 16/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 1.0706 - accuracy: 0.6115 - val_loss: 1.0701 - val_accuracy: 0.6433 - lr: 0.0010\n",
            "Epoch 17/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 1.0424 - accuracy: 0.6250 - val_loss: 1.1262 - val_accuracy: 0.5667 - lr: 0.0010\n",
            "Epoch 18/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 1.0696 - accuracy: 0.6063 - val_loss: 1.0398 - val_accuracy: 0.6333 - lr: 0.0010\n",
            "Epoch 19/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 1.0084 - accuracy: 0.6383 - val_loss: 1.0768 - val_accuracy: 0.5967 - lr: 0.0010\n",
            "Epoch 20/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 1.0099 - accuracy: 0.6356 - val_loss: 1.0431 - val_accuracy: 0.6100 - lr: 0.0010\n",
            "Epoch 21/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.9995 - accuracy: 0.6376 - val_loss: 0.9862 - val_accuracy: 0.6500 - lr: 0.0010\n",
            "Epoch 22/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.9634 - accuracy: 0.6566 - val_loss: 0.9810 - val_accuracy: 0.6667 - lr: 0.0010\n",
            "Epoch 23/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.9632 - accuracy: 0.6533 - val_loss: 0.9788 - val_accuracy: 0.6533 - lr: 0.0010\n",
            "Epoch 24/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.9470 - accuracy: 0.6602 - val_loss: 0.9509 - val_accuracy: 0.6533 - lr: 0.0010\n",
            "Epoch 25/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9333 - accuracy: 0.6642 - val_loss: 0.9562 - val_accuracy: 0.6533 - lr: 0.0010\n",
            "Epoch 26/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.9189 - accuracy: 0.6729 - val_loss: 0.9165 - val_accuracy: 0.6767 - lr: 0.0010\n",
            "Epoch 27/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9120 - accuracy: 0.6744 - val_loss: 0.9349 - val_accuracy: 0.6533 - lr: 0.0010\n",
            "Epoch 28/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.9317 - accuracy: 0.6620 - val_loss: 0.9185 - val_accuracy: 0.6533 - lr: 0.0010\n",
            "Epoch 29/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.8989 - accuracy: 0.6805 - val_loss: 0.8885 - val_accuracy: 0.6800 - lr: 0.0010\n",
            "Epoch 30/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.8958 - accuracy: 0.6776 - val_loss: 0.8915 - val_accuracy: 0.7033 - lr: 0.0010\n",
            "Epoch 31/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.8727 - accuracy: 0.6910 - val_loss: 0.8637 - val_accuracy: 0.6933 - lr: 0.0010\n",
            "Epoch 32/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.8619 - accuracy: 0.6961 - val_loss: 0.8778 - val_accuracy: 0.6733 - lr: 0.0010\n",
            "Epoch 33/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.8594 - accuracy: 0.6948 - val_loss: 0.8699 - val_accuracy: 0.6733 - lr: 0.0010\n",
            "Epoch 34/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.8593 - accuracy: 0.6926 - val_loss: 0.8579 - val_accuracy: 0.6900 - lr: 0.0010\n",
            "Epoch 35/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.8462 - accuracy: 0.6989 - val_loss: 0.8297 - val_accuracy: 0.7100 - lr: 0.0010\n",
            "Epoch 36/1000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.8472 - accuracy: 0.6943 - val_loss: 0.8417 - val_accuracy: 0.6967 - lr: 0.0010\n",
            "Epoch 37/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.8158 - accuracy: 0.7095 - val_loss: 0.7979 - val_accuracy: 0.7300 - lr: 0.0010\n",
            "Epoch 38/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.8078 - accuracy: 0.7126 - val_loss: 0.8470 - val_accuracy: 0.6733 - lr: 0.0010\n",
            "Epoch 39/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.7885 - accuracy: 0.7188 - val_loss: 0.8029 - val_accuracy: 0.7067 - lr: 0.0010\n",
            "Epoch 40/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.7747 - accuracy: 0.7260 - val_loss: 0.7708 - val_accuracy: 0.7333 - lr: 0.0010\n",
            "Epoch 41/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.7518 - accuracy: 0.7339 - val_loss: 0.7617 - val_accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 42/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.7328 - accuracy: 0.7427 - val_loss: 0.7404 - val_accuracy: 0.7400 - lr: 0.0010\n",
            "Epoch 43/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.7203 - accuracy: 0.7413 - val_loss: 0.7256 - val_accuracy: 0.7300 - lr: 0.0010\n",
            "Epoch 44/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.6936 - accuracy: 0.7531 - val_loss: 0.6973 - val_accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 45/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.6618 - accuracy: 0.7669 - val_loss: 0.6950 - val_accuracy: 0.7367 - lr: 0.0010\n",
            "Epoch 46/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.6143 - accuracy: 0.7924 - val_loss: 0.6141 - val_accuracy: 0.8000 - lr: 0.0010\n",
            "Epoch 47/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.5804 - accuracy: 0.8043 - val_loss: 0.5859 - val_accuracy: 0.8033 - lr: 0.0010\n",
            "Epoch 48/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.5378 - accuracy: 0.8272 - val_loss: 0.5416 - val_accuracy: 0.8300 - lr: 0.0010\n",
            "Epoch 49/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.5061 - accuracy: 0.8476 - val_loss: 0.5028 - val_accuracy: 0.8533 - lr: 0.0010\n",
            "Epoch 50/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.4814 - accuracy: 0.8569 - val_loss: 0.5213 - val_accuracy: 0.8400 - lr: 0.0010\n",
            "Epoch 51/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.4593 - accuracy: 0.8660 - val_loss: 0.4367 - val_accuracy: 0.8900 - lr: 0.0010\n",
            "Epoch 52/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.4143 - accuracy: 0.8917 - val_loss: 0.4100 - val_accuracy: 0.8833 - lr: 0.0010\n",
            "Epoch 53/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3839 - accuracy: 0.9029 - val_loss: 0.3793 - val_accuracy: 0.9200 - lr: 0.0010\n",
            "Epoch 54/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3599 - accuracy: 0.9123 - val_loss: 0.3484 - val_accuracy: 0.9200 - lr: 0.0010\n",
            "Epoch 55/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3247 - accuracy: 0.9288 - val_loss: 0.3186 - val_accuracy: 0.9233 - lr: 0.0010\n",
            "Epoch 56/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2963 - accuracy: 0.9403 - val_loss: 0.2933 - val_accuracy: 0.9500 - lr: 0.0010\n",
            "Epoch 57/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2732 - accuracy: 0.9515 - val_loss: 0.2677 - val_accuracy: 0.9567 - lr: 0.0010\n",
            "Epoch 58/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2477 - accuracy: 0.9601 - val_loss: 0.2567 - val_accuracy: 0.9433 - lr: 0.0010\n",
            "Epoch 59/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2467 - accuracy: 0.9547 - val_loss: 0.2491 - val_accuracy: 0.9500 - lr: 0.0010\n",
            "Epoch 60/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2127 - accuracy: 0.9681 - val_loss: 0.2151 - val_accuracy: 0.9567 - lr: 0.0010\n",
            "Epoch 61/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1919 - accuracy: 0.9741 - val_loss: 0.1869 - val_accuracy: 0.9767 - lr: 0.0010\n",
            "Epoch 62/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1788 - accuracy: 0.9765 - val_loss: 0.1792 - val_accuracy: 0.9667 - lr: 0.0010\n",
            "Epoch 63/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1595 - accuracy: 0.9820 - val_loss: 0.1617 - val_accuracy: 0.9767 - lr: 0.0010\n",
            "Epoch 64/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1455 - accuracy: 0.9845 - val_loss: 0.1509 - val_accuracy: 0.9767 - lr: 0.0010\n",
            "Epoch 65/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1319 - accuracy: 0.9874 - val_loss: 0.1384 - val_accuracy: 0.9833 - lr: 0.0010\n",
            "Epoch 66/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1214 - accuracy: 0.9900 - val_loss: 0.1351 - val_accuracy: 0.9733 - lr: 0.0010\n",
            "Epoch 67/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.1659 - accuracy: 0.9665 - val_loss: 0.1178 - val_accuracy: 0.9900 - lr: 0.0010\n",
            "Epoch 68/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0985 - accuracy: 0.9934 - val_loss: 0.1098 - val_accuracy: 0.9867 - lr: 0.0010\n",
            "Epoch 69/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0889 - accuracy: 0.9949 - val_loss: 0.0965 - val_accuracy: 0.9967 - lr: 0.0010\n",
            "Epoch 70/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0808 - accuracy: 0.9958 - val_loss: 0.0900 - val_accuracy: 0.9967 - lr: 0.0010\n",
            "Epoch 71/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0744 - accuracy: 0.9962 - val_loss: 0.0849 - val_accuracy: 0.9967 - lr: 0.0010\n",
            "Epoch 72/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0683 - accuracy: 0.9967 - val_loss: 0.0796 - val_accuracy: 0.9933 - lr: 0.0010\n",
            "Epoch 73/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0622 - accuracy: 0.9971 - val_loss: 0.0712 - val_accuracy: 0.9967 - lr: 0.0010\n",
            "Epoch 74/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0584 - accuracy: 0.9973 - val_loss: 0.0687 - val_accuracy: 0.9967 - lr: 0.0010\n",
            "Epoch 75/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0553 - accuracy: 0.9972 - val_loss: 0.0616 - val_accuracy: 0.9967 - lr: 0.0010\n",
            "Epoch 76/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0489 - accuracy: 0.9978 - val_loss: 0.0551 - val_accuracy: 0.9967 - lr: 0.0010\n",
            "Epoch 77/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0438 - accuracy: 0.9983 - val_loss: 0.0512 - val_accuracy: 0.9967 - lr: 0.0010\n",
            "Epoch 78/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0413 - accuracy: 0.9986 - val_loss: 0.0457 - val_accuracy: 0.9967 - lr: 0.0010\n",
            "Epoch 79/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0401 - accuracy: 0.9984 - val_loss: 0.0670 - val_accuracy: 0.9867 - lr: 0.0010\n",
            "Epoch 80/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.2639 - accuracy: 0.9258 - val_loss: 0.0548 - val_accuracy: 0.9967 - lr: 0.0010\n",
            "Epoch 81/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0382 - accuracy: 0.9986 - val_loss: 0.0415 - val_accuracy: 0.9967 - lr: 0.0010\n",
            "Epoch 82/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0330 - accuracy: 0.9991 - val_loss: 0.0401 - val_accuracy: 0.9967 - lr: 0.0010\n",
            "Epoch 83/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0301 - accuracy: 0.9994 - val_loss: 0.0379 - val_accuracy: 0.9967 - lr: 0.0010\n",
            "Epoch 84/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0283 - accuracy: 0.9995 - val_loss: 0.0344 - val_accuracy: 0.9967 - lr: 0.0010\n",
            "Epoch 85/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0263 - accuracy: 0.9995 - val_loss: 0.0333 - val_accuracy: 0.9967 - lr: 0.0010\n",
            "Epoch 86/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0247 - accuracy: 0.9997 - val_loss: 0.0317 - val_accuracy: 0.9967 - lr: 0.0010\n",
            "Epoch 87/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0231 - accuracy: 0.9997 - val_loss: 0.0289 - val_accuracy: 0.9967 - lr: 0.0010\n",
            "Epoch 88/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0220 - accuracy: 0.9997 - val_loss: 0.0274 - val_accuracy: 0.9967 - lr: 0.0010\n",
            "Epoch 89/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0204 - accuracy: 0.9997 - val_loss: 0.0254 - val_accuracy: 0.9967 - lr: 0.0010\n",
            "Epoch 90/1000\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.0191 - accuracy: 0.9997 - val_loss: 0.0242 - val_accuracy: 0.9967 - lr: 0.0010\n",
            "Epoch 91/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0179 - accuracy: 0.9997 - val_loss: 0.0228 - val_accuracy: 0.9967 - lr: 0.0010\n",
            "Epoch 92/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0168 - accuracy: 0.9998 - val_loss: 0.0210 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 93/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0159 - accuracy: 0.9998 - val_loss: 0.0199 - val_accuracy: 0.9967 - lr: 0.0010\n",
            "Epoch 94/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0148 - accuracy: 0.9998 - val_loss: 0.0184 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 95/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0138 - accuracy: 0.9997 - val_loss: 0.0175 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 96/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0131 - accuracy: 0.9998 - val_loss: 0.0154 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 97/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0122 - accuracy: 0.9998 - val_loss: 0.0151 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 98/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0114 - accuracy: 0.9998 - val_loss: 0.0132 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 99/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0108 - accuracy: 0.9998 - val_loss: 0.0127 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 100/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0101 - accuracy: 0.9997 - val_loss: 0.0116 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 101/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0095 - accuracy: 0.9999 - val_loss: 0.0116 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 102/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3166 - accuracy: 0.9222 - val_loss: 0.0597 - val_accuracy: 0.9867 - lr: 0.0010\n",
            "Epoch 103/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0251 - accuracy: 0.9980 - val_loss: 0.0154 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 104/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0119 - accuracy: 0.9999 - val_loss: 0.0125 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 105/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0103 - accuracy: 0.9999 - val_loss: 0.0113 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 106/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0095 - accuracy: 0.9999 - val_loss: 0.0104 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 107/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0088 - accuracy: 0.9999 - val_loss: 0.0098 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 108/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0084 - accuracy: 0.9998 - val_loss: 0.0097 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 109/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0080 - accuracy: 0.9999 - val_loss: 0.0088 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 110/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0076 - accuracy: 0.9999 - val_loss: 0.0086 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 111/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0072 - accuracy: 0.9999 - val_loss: 0.0082 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 112/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0068 - accuracy: 0.9999 - val_loss: 0.0079 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 113/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0065 - accuracy: 0.9999 - val_loss: 0.0073 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 114/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0063 - accuracy: 0.9999 - val_loss: 0.0070 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 115/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 116/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0058 - accuracy: 0.9999 - val_loss: 0.0063 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 117/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0056 - accuracy: 0.9999 - val_loss: 0.0061 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 118/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0053 - accuracy: 0.9999 - val_loss: 0.0056 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 119/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0051 - accuracy: 0.9999 - val_loss: 0.0057 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 120/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 121/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0047 - accuracy: 0.9999 - val_loss: 0.0050 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 122/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 123/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 124/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0041 - accuracy: 0.9999 - val_loss: 0.0045 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 125/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0039 - accuracy: 0.9999 - val_loss: 0.0046 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 126/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0038 - accuracy: 0.9999 - val_loss: 0.0041 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 127/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 128/1000\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 129/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 130/1000\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 131/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 132/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 133/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 134/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9933 - lr: 0.0010\n",
            "Epoch 135/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.5693 - accuracy: 0.8735 - val_loss: 0.0263 - val_accuracy: 0.9967 - lr: 0.0010\n",
            "Epoch 136/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0141 - accuracy: 0.9995 - val_loss: 0.0092 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 137/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 138/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 139/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 140/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0056 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 141/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 142/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 143/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 144/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 145/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 146/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 147/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 148/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 149/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 150/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 151/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 152/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 153/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 154/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 155/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 156/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 157/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 158/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 159/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 160/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 161/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 162/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 163/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000 - lr: 1.0000e-06\n",
            "Epoch 164/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000 - lr: 1.0000e-06\n",
            "Epoch 165/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000 - lr: 1.0000e-06\n",
            "Epoch 166/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000 - lr: 1.0000e-06\n",
            "Epoch 167/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000 - lr: 1.0000e-06\n",
            "Epoch 168/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000 - lr: 1.0000e-06\n",
            "Epoch 169/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000 - lr: 1.0000e-06\n",
            "Epoch 170/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000 - lr: 1.0000e-06\n",
            "Epoch 171/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000 - lr: 1.0000e-06\n",
            "Epoch 172/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000 - lr: 1.0000e-06\n",
            "Epoch 173/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000 - lr: 1.0000e-07\n",
            "Epoch 174/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000 - lr: 1.0000e-07\n",
            "Epoch 175/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000 - lr: 1.0000e-07\n",
            "Epoch 176/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000 - lr: 1.0000e-07\n",
            "Epoch 177/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000 - lr: 1.0000e-07\n",
            "Epoch 178/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000 - lr: 1.0000e-07\n",
            "Epoch 179/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000 - lr: 1.0000e-07\n",
            "Epoch 180/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000 - lr: 1.0000e-07\n",
            "Epoch 181/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000 - lr: 1.0000e-07\n",
            "Epoch 182/1000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000 - lr: 1.0000e-07\n",
            "Epoch 182: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Evaluation"
      ],
      "metadata": {
        "id": "UD-lqoupcnp0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "FKiRHwsphibD"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['loss', 'val_loss'], loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "7jyG2ynNhxCs",
        "outputId": "b3f3f024-6f7b-42df-db87-2661bad2cfe5"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = model.predict(X_test, batch_size=BATCH_SIZE, verbose=0)\n",
        "\n",
        "expected = [decode(x) for x in y_test]\n",
        "predicted = [decode(x) for x in result]\n",
        "\n",
        "for i in range(TEST_SAMPLES):\n",
        "\tprint(f'{decode(X_test[i])} =    (Expected={expected[i]},      Predicted={predicted[i]})')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ykle3jO2cpNA",
        "outputId": "e41dd885-802e-4b09-803f-8d43167f881c"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40+67   =    (Expected=107,      Predicted=107)\n",
            "83+17   =    (Expected=100,      Predicted=100)\n",
            "34+50   =    (Expected=84 ,      Predicted=84 )\n",
            "89+2    =    (Expected=91 ,      Predicted=91 )\n",
            "89+37   =    (Expected=126,      Predicted=126)\n",
            "16+48   =    (Expected=64 ,      Predicted=64 )\n",
            "7+12    =    (Expected=19 ,      Predicted=19 )\n",
            "74+68   =    (Expected=142,      Predicted=142)\n",
            "55+75   =    (Expected=130,      Predicted=130)\n",
            "42+61   =    (Expected=103,      Predicted=103)\n",
            "90+88   =    (Expected=178,      Predicted=178)\n",
            "69+10   =    (Expected=79 ,      Predicted=79 )\n",
            "54+60   =    (Expected=114,      Predicted=114)\n",
            "46+56   =    (Expected=102,      Predicted=102)\n",
            "95+87   =    (Expected=182,      Predicted=182)\n",
            "74+33   =    (Expected=107,      Predicted=107)\n",
            "64+20   =    (Expected=84 ,      Predicted=84 )\n",
            "9+9     =    (Expected=18 ,      Predicted=18 )\n",
            "39+8    =    (Expected=47 ,      Predicted=47 )\n",
            "3+62    =    (Expected=65 ,      Predicted=65 )\n",
            "24+92   =    (Expected=116,      Predicted=116)\n",
            "59+88   =    (Expected=147,      Predicted=147)\n",
            "32+17   =    (Expected=49 ,      Predicted=49 )\n",
            "18+82   =    (Expected=100,      Predicted=100)\n",
            "30+9    =    (Expected=39 ,      Predicted=39 )\n",
            "9+25    =    (Expected=34 ,      Predicted=34 )\n",
            "71+26   =    (Expected=97 ,      Predicted=97 )\n",
            "87+89   =    (Expected=176,      Predicted=176)\n",
            "88+70   =    (Expected=158,      Predicted=158)\n",
            "14+97   =    (Expected=111,      Predicted=111)\n",
            "12+39   =    (Expected=51 ,      Predicted=51 )\n",
            "98+67   =    (Expected=165,      Predicted=165)\n",
            "81+54   =    (Expected=135,      Predicted=135)\n",
            "94+63   =    (Expected=157,      Predicted=157)\n",
            "27+13   =    (Expected=40 ,      Predicted=40 )\n",
            "24+65   =    (Expected=89 ,      Predicted=89 )\n",
            "94+71   =    (Expected=165,      Predicted=165)\n",
            "48+53   =    (Expected=101,      Predicted=101)\n",
            "17+26   =    (Expected=43 ,      Predicted=43 )\n",
            "20+42   =    (Expected=62 ,      Predicted=62 )\n",
            "34+83   =    (Expected=117,      Predicted=117)\n",
            "3+48    =    (Expected=51 ,      Predicted=51 )\n",
            "18+38   =    (Expected=56 ,      Predicted=56 )\n",
            "65+59   =    (Expected=124,      Predicted=124)\n",
            "37+47   =    (Expected=84 ,      Predicted=84 )\n",
            "18+44   =    (Expected=62 ,      Predicted=62 )\n",
            "68+89   =    (Expected=157,      Predicted=157)\n",
            "99+79   =    (Expected=178,      Predicted=178)\n",
            "55+49   =    (Expected=104,      Predicted=104)\n",
            "28+77   =    (Expected=105,      Predicted=105)\n",
            "36+40   =    (Expected=76 ,      Predicted=76 )\n",
            "33+54   =    (Expected=87 ,      Predicted=87 )\n",
            "3+98    =    (Expected=101,      Predicted=101)\n",
            "79+78   =    (Expected=157,      Predicted=157)\n",
            "19+50   =    (Expected=69 ,      Predicted=69 )\n",
            "18+58   =    (Expected=76 ,      Predicted=76 )\n",
            "61+37   =    (Expected=98 ,      Predicted=98 )\n",
            "6+55    =    (Expected=61 ,      Predicted=61 )\n",
            "74+35   =    (Expected=109,      Predicted=109)\n",
            "21+33   =    (Expected=54 ,      Predicted=54 )\n",
            "11+70   =    (Expected=81 ,      Predicted=81 )\n",
            "12+48   =    (Expected=60 ,      Predicted=60 )\n",
            "69+4    =    (Expected=73 ,      Predicted=73 )\n",
            "24+7    =    (Expected=31 ,      Predicted=31 )\n",
            "46+4    =    (Expected=50 ,      Predicted=50 )\n",
            "84+29   =    (Expected=113,      Predicted=113)\n",
            "50+20   =    (Expected=70 ,      Predicted=70 )\n",
            "12+87   =    (Expected=99 ,      Predicted=99 )\n",
            "76+98   =    (Expected=174,      Predicted=174)\n",
            "57+61   =    (Expected=118,      Predicted=118)\n",
            "71+18   =    (Expected=89 ,      Predicted=89 )\n",
            "25+68   =    (Expected=93 ,      Predicted=93 )\n",
            "25+34   =    (Expected=59 ,      Predicted=59 )\n",
            "24+25   =    (Expected=49 ,      Predicted=49 )\n",
            "26+81   =    (Expected=107,      Predicted=107)\n",
            "12+69   =    (Expected=81 ,      Predicted=81 )\n",
            "21+62   =    (Expected=83 ,      Predicted=83 )\n",
            "75+65   =    (Expected=140,      Predicted=140)\n",
            "21+66   =    (Expected=87 ,      Predicted=87 )\n",
            "18+27   =    (Expected=45 ,      Predicted=45 )\n",
            "64+47   =    (Expected=111,      Predicted=111)\n",
            "67+40   =    (Expected=107,      Predicted=107)\n",
            "14+22   =    (Expected=36 ,      Predicted=36 )\n",
            "90+15   =    (Expected=105,      Predicted=105)\n",
            "32+40   =    (Expected=72 ,      Predicted=72 )\n",
            "25+27   =    (Expected=52 ,      Predicted=52 )\n",
            "81+59   =    (Expected=140,      Predicted=140)\n",
            "5+26    =    (Expected=31 ,      Predicted=31 )\n",
            "33+17   =    (Expected=50 ,      Predicted=50 )\n",
            "4+38    =    (Expected=42 ,      Predicted=42 )\n",
            "65+39   =    (Expected=104,      Predicted=104)\n",
            "47+73   =    (Expected=120,      Predicted=120)\n",
            "57+97   =    (Expected=154,      Predicted=154)\n",
            "89+43   =    (Expected=132,      Predicted=132)\n",
            "25+41   =    (Expected=66 ,      Predicted=66 )\n",
            "68+19   =    (Expected=87 ,      Predicted=87 )\n",
            "40+49   =    (Expected=89 ,      Predicted=89 )\n",
            "11+99   =    (Expected=110,      Predicted=110)\n",
            "26+44   =    (Expected=70 ,      Predicted=70 )\n",
            "37+65   =    (Expected=102,      Predicted=102)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " "
      ],
      "metadata": {
        "id": "r3ZBK8cae0ZJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}